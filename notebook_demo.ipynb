{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6401d398",
   "metadata": {},
   "source": [
    "## Customized Chest CT Anomaly Segmentation Algorithm from AWS Marketplace \n",
    "\n",
    "This deep learning based solution provides chest CT analysis with precise segmentation of various anomalies and chest conditions.\n",
    "\n",
    "This sample notebook shows you how to execute Customized Chest CT Anomaly Segmentation Algorithm from AWS Marketplace \n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**u\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to For Seller to update: clean-sentiment-classification-labels. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure dataset](#B.-Configure-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Execute optimization model](#3.-Execute-optimization-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Execute model](#3.2-Execute-model)\n",
    "    1. [Visualize Output](#3.3-Inspect-the-Output-in-S3)\n",
    "1. [Clean-up](#4.-Clean-up)\n",
    "\t1. [Unsubscribe to the listing (optional)](#Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff4b84",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5688a",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page **Clean Sentiment Classification Labels**\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacc965",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f88ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefixes\n",
    "common_prefix = \"medseglab_demo_test\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adf82f",
   "metadata": {},
   "source": [
    "### Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our Amazon SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c6c24",
   "metadata": {},
   "source": [
    "### Upload the data for training\n",
    "\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3. For the purposes of this example, we're using an open source dataset mentioned in github link: https://github.com/Mphasis-ML-Marketplace/medseglab-demo/tree/main\n",
    "\n",
    "We can use use the tools provided by the Amazon SageMaker Python SDK to upload the data to a default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)\n",
    "print(\"Training Data Location \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b26f6",
   "metadata": {},
   "source": [
    "### Creating Training Job using Algorithm ARN\n",
    "\n",
    "Please put in the algorithm arn you want to use below. This can either be an AWS Marketplace algorithm you subscribed to (or) one of the algorithms you created in your own account.\n",
    "\n",
    "The algorithm arn listed below belongs to the Scikit Decision Trees product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e515de",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn = \"medseglab-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc828c",
   "metadata": {},
   "source": [
    "Configure hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"bs\": 16, \"epochs\": 2} # batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ace98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.algorithm import AlgorithmEstimator\n",
    "\n",
    "algo = AlgorithmEstimator(\n",
    "    algorithm_arn=algorithm_arn,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.g5.2xlarge\", \n",
    "    base_job_name=\"medseglab-v0-test\",\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df09b97",
   "metadata": {},
   "source": [
    "### Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Now run the training job using algorithm arn %s in region %s\"\n",
    "    % (algorithm_arn, sagemaker_session.boto_region_name)\n",
    ")\n",
    "algo.fit({\"training\": training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64283d6",
   "metadata": {},
   "source": [
    "### Batch Transform Job\n",
    "Now let's use the model built to run a batch inference job and verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_WORKDIR = \"data/inference\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Batch Transform Data Location \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf93169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer = algo.transformer(1, \"ml.p2.xlarge\")\n",
    "transformer.transform(transform_input, content_type=\"application/zip\")\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d277bd",
   "metadata": {},
   "source": [
    "### Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = \"{}/{}.out\".format(parsed_url.path[1:], \"frames.zip\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client(\"s3\")\n",
    "\n",
    "with open(\"response.zip\", \"wb\") as FO:\n",
    "    s3_client.download_fileobj(Bucket=sagemaker_session.default_bucket(), Key=file_key, Fileobj=FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir batch_transform_output/\n",
    "!unzip response.zip -d ./batch_transform_output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f39f1",
   "metadata": {},
   "source": [
    "### Live Inference Endpoint\n",
    "Finally, we demonstrate the creation of an endpoint for live inference using this AWS Marketplace algorithm generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "predictor = algo.deploy(1, \"ml.p2.xlarge\", serializer=IdentitySerializer(content_type='image/png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417397da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"img_payload.png\"\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_payload_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(image_payload_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24117735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_image = Image.open(BytesIO(response)).convert(\"RGB\")\n",
    "labeled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec47f82",
   "metadata": {},
   "source": [
    "### Cleanup the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660630d",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
